\lsr{} serves as a functioning system, capable of performing complex statistical analyses over larger-than-memory datasets.
The implementation of this system makes use of a layered approach, wherein each layer targets a different category of user.
A description of the implementation structure of \lsr{} follows.

The system is supported at the base layer by the \pkg{orcv} package, which exists as an in-memory threaded TCP message queue.
It was created specifically for \pkg{largescaler}, making use of the \proglang{C} API for \R{}, though it is sufficiently general to serve the wider purpose of a message queue for the transfer of \R{} objects between \R{} processes.
Central to the functionality of \pkg{orcv} is its multithreaded operation, allowing transfers to take place in the background of the host \R{} process, thereby not blocking computation.
The core user-base of this package is intended as developers on \lsr{}.

Sitting on top of \pkg{orcv}, the package \pkg{chunknet} enables the creation of detached nodes, which use \pkg{orcv} to communicate, and operate using their own event loops populated via the queue provided by \pkg{orcv}.
The types of these nodes provided by the package are worker nodes, and a location service, which serve to operate on and locate chunks, respectively.
The client interface is also provided by \pkg{chunknet}, allowing interaction with chunks as the major user-facing class in this package.
Chunks can be interacted with individually, or collected as part of arbitrary-dimension arrays, over which distributed \code{apply}'s and the like are defined.
The main users of this package are intended to be power-users of distributed statistical algorithms who seek to maximise performance.

The package that meets the demanding statistician as referenced is given by the \lsr{} package, which offers the distributed object as an abstracted class where chunk distribution is handled implicitly by the package, freeing the statistician to focus on model creation.
Further features offered by the package include distributed environment setup, an automatic distributed function converter, distributed functional programming tools such as a reduce operator, distributed I/O, checkpointing, shuffling of datasets with implicit load-balancing, and a \pkg{dplyr} interface to distributed dataframes\cite{dplyr}.
