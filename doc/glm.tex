We now move to the central problem that prompted this work; defining a novel distributed statistical algorithm.
Rather than detour with a truly novel algorithm, it is prefereable to engage with something that is familiar, but holds a fairly generic form that novel analyses often share.
Let's consider distributed LASSO regression, using the Alternating Direction Method of Multipliers, as described by \textcite{mateos2010}.
We begin by assessing the mathematical form in \cref{sec:mathlasso}, followed by the ``standard R'' means of writing a chunked algorithm in contraposition with the \lsr{} manner in \cref{sec:rlasso}.

\subsection{Distributed LASSO Mathematical Definition}\label{sec:mathlasso}

This section seeks to give a brief taste of what a mathematical formulation for a distributed statistical model takes, in order to demonstrate the semantic and syntactic similarity to \lsr{} in \cref{sec:rlasso}.
A richer description, with significant background, is given in \textcite{boyd2011}.

We begin with a description of the input data, as given in \cref{eq:mathlassodata}

\eq{mathlassodata}

The starting data includes a column block matrix of explanatory variables, $A$, consisting of $N$ submatrices.
This is equivalent to a distributed object consisting of $N$ chunks.
Here, each chunk is of the standard form where rows are individual observations and columns are variables.
We also have a block matrix $b$ of the same number of chunks, with each chunk being the column vector of response variables to the corresponding $A$ chunks.

The standard form of the LASSO as an optimisation problem is expressed in \cref{eq:mathlassointention}.

\eq{mathlassointention}

The body of the ADMM loop is given by \cref{eq:mathlassoloop}.
Of note is the complexity, the presence of iteration, and the interactions between sets of chunks getting reduced and emerged.

\eq{mathlassoloop}

\subsection{Distributed LASSO R Description}\label{sec:rlasso}

This subsection gives both base \R{} syntax for working with a local chunked dataset, as well as the minimal changes that are required when using \lsr{} to transform the expressions to handle distributed data.
The core substance of this subsection is to demonstrate the ease with which \R{} is able to meet a mathematical definition, and the successive ease by which \lsr{} is able to turn that into a truly distributed algorithm.
As in \cref{sec:mathlasso}, the working example is given of distributed LASSO.
Consider first some chunked data, given as a diff in \cref{tab:chunked-comp}.
In the diff, semantic differences are demarcated through underlining, with shared code given centrally, with no dividing line.
On the left of the diff we have how the LASSO as described might be encoded in the absence of the API, assuming that the data fit into memory, and on the right, we make use of large scale \R{} with no such constraining assumption.

In the \lsr{} code, distributed data may come from multiple files and multiple hosts holding the chunks, and this is easily provided for.
The distribution comes with the necessity to carefully differentiate between the reference of the distributed object, and the distributed object itself.
The ability to explicitly distribute local values to particular locations is also demonstrated here.

\tab{chunked-comp}{Comparison of reading in chunks of data}

The layout of the data is followed by the iterative loop, given in \cref{tab:loop-comp}.
Within the iterative loop, we can see that very little is actually needed to be changed in order to distribute this algorithm.
We make use of a function that operates on distributed objects which we define ourselves in the successive diff, as well as the emerge to bring the distributed local as we saw before.

\tab{loop-comp}{Comparison of the iterative loop}

Note the significantly simplified and reduced logic in switching to \lsr{}, which bears a far closer resemblance to the mathematical description.
The \code{x-update} function given above is exemplary of the approach provided by \lsr{}, which allows for the switching of a local to a distributed function through the higher-order \code{dist} function, as demonstrated in \cref{tab:x-update}:

\tab{x-update}{Comparison of the \code{x-update} functions}

And this serves to define a distributed LASSO, using ADMM.
