\subsection{Introduction}\label{subsec:lsf-intro}

To guide the development of the platform, desirable features are drawn from existing platforms; inferred as logical extensions; and arrived at through identification of needs.
Some features are mutually exclusive, others are suggestive of each other, but are worth considering and contrasting their merits.

\subsection{Feature List}\label{subsec:feature-list}

A list of features and their descriptions follows:

\begin{description} \item[Distributed Computation] The ability to spread computation and data over separate computers.
		The value of distributed computing is well recognised for large-scale computing, in the increased capacity for processing, memory, and storage.
		Distributed computing typically gains computational speedup through parallel processing; both Amdahl's law and Gustafson's law give theoretical speedups for parallel jobs \cites{amdahl1967law,gustafson1988law}.
		In addition, each node typically adds more working memory to the distributed system, allowing for larger datasets to be manipulated in-memory.
		For exceedingly large datasets, the benefits of distributed file systems commonly allow for resilient storage, with well-regarded examples including HDFS and the Google File System it is based upon \cites{shvachko2010hadoop,ghemawat2003google}.
	\item[Evaluation of User-Specified Code]
		The ability to make use of user-specified code in processing.
		Most \R{} packages for large-scale computing interact well with arbitrary code, however they typically have some limitations, such as an inability to recognise global variables, as is the case with \pkg{sparklyr} and to a lesser extent future \cites{sparklyr2020limitations,microsoft20}.
	\item[Native Support for Iteration]
		The ability to process user-specified code involving iteration over the
		whole dataset natively, keeping results in memory between iterations.
		This reflects the inherently iterative nature of many statistical algorithms.
		Furthermore, this shouldn't initiate a new job or process for every new iteration.
		This is seen as important enough that it serves as a major motivating factor behind \pkg{Spark}'s development, overcoming a perceived major deficiency of \pkg{Hadoop} by \pkg{Spark}'s developers \cite{zaharia2010spark}.
	\item[Object Persistence at Nodes]
		The ability to retain objects in-memory at their point of processing.
		The standard motivation for such a feature revolves around a reduction in data movement -- the data movement otherwise slowing down processing enormously through forcing programs to be bound by networking speeds, typically orders of magnitude lower than in-memory data access speeds.
	In-memory persistence is closely related to the capacity for iterative code evaluation in a distributed system, and was similarly referenced by the \pkg{Spark} developers as an apparent benefit of \pkg{Spark}\cite{zaharia2010spark}. The concept of spatial locality of reference is described in greater detail by \textcite{denning2005locality}.
	\item[Support for Distributed File Systems]
		Capacity to work with data and computation on distributed file systems,
		with a particular target of \pkg{Hadoop}
		Distributed File System (HDFS).
		As a well-established distributed file system, HDFS is targeted by a number of \R{} packages, as well as serving as a file system base for other platforms such as \pkg{Spark} \cite{analytics:_rhadoop_wiki} \cite{deltarho:_rhipe}\cite{urbanek20}\cite{zaharia2016apache}.
		HDFS offers several features that make it particularly attractive as a filesystem for a large-scale statistical analysis; being distributed and capable of running on commodity hardware allows for truly big data analysis.
		In addition, the system is built to be resilient to hardware failure, so long-running analyses aren't cut short or forced to revert to a checkpoint because of singular component failure \cite{shvachko2010hadoop}.
	\item[Ease of Setup]
		Is setup suitable for a computationally-focussed statistician, or does
		it require a system administrator?
		At its base, \R{} is a statistical programming language \cite{rcore2020intro}.
		The particular skills of statisticians seldom correspond to the those requisite of system administration, with such a focus unlikely to compete successfully with their main research.
		Ease of deployment can determine a platform's success, with such a feature being one of the many motivations for the use and development of tools such as Docker in recent years.
		The easiest possible setup would be a regular \code{install-packages}, with no more than several lines specifying the platform configuration.
	\item[Inter-Node Communication]
		Can any pair of nodes communicate with each other, or do they only
		report to a master node?
		While many tasks process efficiently within a standard master-worker architecture, and inter-node communication is inherently expensive, there is still a large class of tasks that benefit from inter-node communication\cite{walker1996mpi}; particularly graph-based statistical methods.
	\item[Interactive Usage]
		The ability to make use of the package in an interactive \R{} session,
		without mandatory batch execution.
		A major benefit of \R{} as being interpreted is the availability of the REPL.
		The benefits of interactivity stemming from a REPL are well-documented, most notably aiding debugging \cite{mccarthy1978history}.
		For statistical analyses in particular, interactive analyses play a major role in exploratory data analysis, wherein insights can be tested and arrived at rapidly with an interactive session.
	\item[Backend Decoupling]
		The implementation is maintained entirely separately to the interface.
		This is standard in most of the performant parallel \R{} systems as described by \textcite{eddelbuettel2019parallel}, including \pkg{foreach} as a key example\cite{microsoft20}.
		As a software pattern, this is a case of separation of concerns, described in detail by \textcite{dijkstra1982role}.
		Such a pattern fosters modularity and allows for a broader range of backends to be made use of, maximising the uptake of the platform.
		The ability for a system to adhere to a similar interface despite changes in internal behaviour is additionally useful for the sake of referential transparency, which prevents the need to rewrite programs upon making changes, as well as for human-computer interaction considerations \cites{sondergaard1990Rtda,norman2013design}.
		For example, the \pkg{foreach} package can change parallel adaptors in a single line of setup, without needing any changes made in the code referencing future, despite making use of a different internal interface \cite{weston19:_using}.
	\item[Evaluation of Arbitrary Classes]
		Any class, including user-defined classes, can be used in evaluation.
		There is proven value in rich user-defined objects, with the weight of much of the object-oriented programming paradigm serving to further that point \cite{dahl2004simula}.
		Conversely, many major packages limit themselves through provisioning only a few classes, such as \pkg{pbdDMAT} with distributed matrices, or the Tidyverse and its derivatives including \pkg{sparklyr} with ``tibbles'' \cites{pbdDMATpackage,wickham2019welcome} \item[Package-specific API] The platform is primarily explicitly programmed against at a package-specific interface.
		This is in contrast to packages mostly providing methods which overload standard generics or language structure; at a loss of general transparency, direct API's can ensure greater encapsulation and a closer mapping of code with the underlying implementation, thus potentially resulting in performance gains \cite{bierhoff2009api}.
		An example in \R{} is the interface to the \pkg{foreach} package not overloading the existing for-loop syntax in \R{}, but defining its own specific interface \cite{microsoft20}.
	\item[Methods for Standard Generics]
		The platform is primarily programmed against using a polymorphic
		interface, with the package methods taking advantage of common generics.
		\pkg{pbdDMAT} takes this approach, as well as \pkg{bigmemory}, in providing
		matrix-like classes which are operated upon using standard matrix
		generics \cites{pbdDMATpackage,kane13:bigmemory}.
	\item[Methods for \pkg{dplyr}
	Generics] The platform makes use of \pkg{dplyr} functions as the primary set of generics to program over.
		Using a \pkg{dplyr} interface is a common trend in several \R{} packages including \pkg{sparklyr}, \pkg{disk.frame}, and many database interfaces \cites{luraschi20,zj20}.
		Such an interface is claimed by the \pkg{dplyr} creators to aid beginners through being simple to remember \cite{wickham2019welcome}.
		In this way, it may serve to ease the learning curve for the platform.
\end{description}

\subsection{Comparison Table}\label{subsec:comp-tab}

\widetab{feature-comp}{Comparison of common large scale features among major \R{} packages}

Consider \cref{tab:feature-comp}, with elaboration given in the enumeration below:

\begin{enumerate} \item\label{itm:x1} Use of HDFS through \pkg{rhdfs}\cite{revo2013rhdfs}, and MapReduce through \pkg{rmr2}\cite{revo2014plyrmr}.
	\item\label{itm:x2}
	Use of \pkg{Spark}\cite{luraschi20}.
	\item\label{itm:x3}
	Distributed computation performed by \pkg{pbdMPI}, with support for several remote messaging protocols\cites{Chen2012pbdMPIpackage,Schmidt2015pbdCSpackage}.
	\item\label{itm:x4}
	Through the use of additional packages such as \pkg{doMPI} and \pkg{sparklyr}\cites{weston17,luraschi20}.
	\item\label{itm:x5} \pkg{rmr2}\cite{revo2015rmr2} allows for arbitrary \R{} code to be executed through MapReduce.
	\item\label{itm:x6}
	Provides \code{mutate} function to enable user-defined code, however there are limitations in not being capable of parsing global variables.
	\item\label{itm:x7}
	Adhering to a SPMD paradigm.
	\item\label{itm:x8}
	Many functions used for grouped summarisation are only estimates, such as \code{median}\cite{zj19:_group_by}.
	\item\label{itm:x9} \code{dopar} accepts any expression, and tries its best to handle references to global variables, however it is still recommended to manually define the global references as well as packages used.
	\item\label{itm:x10}
	See \cref{sec:review-iteration-sparklyr}.
	\item\label{itm:x11} \pkg{foreach} makes use of iterators, which can be defined to perform recurrence relations (see \cref{sec:review-foreach}) but these rely on closures and may in fact be slower than serial relations.
	\item\label{itm:x12}
	Direct access to HDFS through \pkg{rhdfs}\cite{revo2013rhdfs}.
	\item\label{itm:x13}
	Allows for \pkg{Spark} over HDFS, but offers no HDFS-specific filesystem manipulation functions.
	\item\label{itm:x14}
	Through \pkg{sparklyr} as a backend.
	\item\label{itm:x15}
	Source repositories only exist on GitHub, following a non-standard package structure at the root level, and \pkg{Hadoop} is required to be set up beforehand.
	\item\label{itm:x16}
	Installs from CRAN, requires \pkg{Spark} set up beforehand and environmental variables configured.
	\item\label{itm:x17}
	Installation can be performed with \code{install-packages} alongside the installation of \pkg{OpenMPI} externally.
	\item\label{itm:x18}
	Inter-node communication facilitated through \pkg{pbdMPI} wrappers to standard MPI communication functions such as \code[c]{scatter}, \code[c]{gather}, \code[c]{send}, etc. \item\label{itm:x19} While the collection is separate from \pkg{Hadoop}, it is entirely tied to \pkg{Hadoop} and MapReduce, and can't be switched to any other distributed platform.
	\item\label{itm:x20}
	Package tied to \pkg{Spark} as evaluative backend.
	\item\label{itm:x21}
	Tied to the usage of the \pkg{MPI} protocol.
	\item\label{itm:x22}
	Within the \code{mapreduce} function from \pkg{rmr2}, no prescription is given for any particular class over another.
	\item\label{itm:x23}
	S3 Objects that have an \code{sdf-import} method implemented can make use of the \code{sdf-copy-to} function to copy objects from \R{} to \pkg{Spark}.
	\item\label{itm:x24}
	Arbitrary classes may be made use of and passed through the communicator generics when methods are defined for them, using \pkg{pbdMPI}.
	\item\label{itm:x25} \pkg{foreach} makes use of iterator objects, which any class can inherit from to define \code{nextElem}.
	\item\label{itm:x26} \pkg{rmr2} has the package-specific \code{mapreduce} function as the primary interface.
	\item\label{itm:x27} \pkg{pbdMPI} provides package-specific generics to use and define further methods for.
	\item\label{itm:x28} \pkg{pbdDMAT} provides a distributed matrix class with methods defined to make transparent usage of standard matrix manipulation generics.
	\item\label{itm:x29}
	The collection has suffered from the lack of updates; \pkg{plyrmr} provides functionality that is near-transparent to \pkg{plyr}, but this is still some distance from \pkg{dplyr}\cite{revo2014plyrmr}.
	\item\label{itm:x30}
	The principal interaction is via \pkg{dplyr} generics, albeit with a difference of lazy evaluation.
\end{enumerate}
