This section walks through the usage of the API of the \lso{} module to perform basic operations, with the intention of granting intuitive familiarity with the system in small steps.
The practical use of the API as illustrated is delivered in \cref{ch:lasso}.

Consider the highest level first: \lsm{}.
How would a pre-made model fit larger than memory data?
There is no simpler form: Load the data, then fit the model with a given function.
This assumes a running cluster, which is described later on, due to the additional details required for a cluster setup.
Load the data with some function provided by \lso{} to read distributed data in as a distributed object, with some \code{read-dist} function.
\lso{} provides the \code{read-dcsv} function to read \file{csv} files distributed across various hosts and filesystems.
This may be stored as in \cref{lst:read-dcsv-ex}.

\src{read-dcsv-ex}{Example distributed \file{csv} read}

Following this, a model function may be run over the distributed object; with a GLM as an example in \cref{lst:dglm-ex}.

\src{dglm-ex}{Example distributed GLM}

And the distributed model has been fit.
This is the topmost interface that all lower layers of abstraction aim to support.
The primary novelty provided is of easy definition of custom models, so let's consider one layer down, examining some of the provided functionality which aids the creation of custom models.
Actual implementation of a custom model is given in \cref{ch:lasso}.

In our exploration of \lso{}, consider first a simple operation of summation.
Given some vector $x$ that is broken up into $j$ chunks, yielding $j$ sub-vectors of length $i$.
Due to associativity the sum of the whole is the sum of the sum of the parts, as shown in \cref{eq:sum}.

\eq{sum}

In an effort to maintain as close proximity as possible between the mathematical description and the provided interface, this may be written in \lso{} as in \cref{lst:dsum}

\src{dsum}{Example distributed summation}

Here, the \code{d} applicator function transforms the base \code{sum} function to work over distributed objects, in this example given by \code{x}.
\code{sum} is therefore sent to each chunk, yielding a new distributed object as the output.
This output distributed object can be brought back to the requesting client and combined using the provided \code{emerge} function, yielding a regular \R{} numeric vector of sums.
This vector of sums may then be summed as normal, providing the final result.
The given example is actually a very simple application of map-reduce, and could effectively serve as the \code{sum} method for distributed objects

Consider something slightly more complex: the arithmetic mean.
Again, a chunked mathematical description is given in \cref{eq:dmean}

\eq{dmean}

A related means of specification through \lso{} is possible, given in \cref{lst:dmean}

\src{dmean}{Distributed mean definition}

Here we build on the distributed sum introduced above, but the total length of The distributed object is relevant as the denominator.
Assuming a \code{sum} method for distributed objects as described, and the math group generic defined in a similar fashion, the denominator is defined using the same \code{d} function that sends a \code{length} computation to all of the chunks.

Finally, consider the cumulative sum.
It is important in this case to think of chunks as being in series, which is determined by the structure of the distributed object reference.
The main difference between a non-distributed and a distributed version of cumulative sum is that for each chunk in the series, computation requires the cumulative sum of the previous chunk as a starting value.
Using a chunked mathematical description, cumulative sum may be described by \cref{eq:dcumsum}.

\eq{dcumsum}

This can be expressed in a functional manner using the \code{reduce} operator, also known as a \code{fold}, and the \lso{} framework provides a distributed form of such a function, where the results of one chunk are sent as the initial value to the reduce function as applied to the next chunk and so on in series.
An example of a reduce operation is given in \cref{fig:dreduce}.

\fig{dreduce}{Example distributed reduce pattern from controlling process.}

This is put to use for cumulative sum by \lso{} by \cref{lst:dcumsum}.

\src{dcumsum}{Distributed cumulative sum definition.}

A distributed object is returned that by default just holds the final accumulation, consisting of one single chunk.
