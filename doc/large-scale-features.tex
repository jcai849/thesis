\hypertarget{a-survey-of-large-scale-platform-features}{%
  \section{A Survey of Large-Scale Platform
    Features}\label{a-survey-of-large-scale-platform-features}}

\hypertarget{sec:intro}{%
  \subsection{Introduction}\label{sec:intro}}

To guide the development of the platform, desirable features are drawn
from existing platforms; inferred as logical extensions; and arrived at
through identification of needs. Some features are mutually exclusive,
others are suggestive of each other, but are worth considering and
contrasting their merits.

\hypertarget{sec:feature-list}{%
  \subsection{Feature List}\label{sec:feature-list}}

A list of features and their descriptions follows:

\begin{description}
  \item[Distributed Computation]
    The ability to spread computation and data over separate computers. The
    value of distributed computing is well recognised for large-scale
    computing, in the increased capacity for processing, memory, and
    storage. Distributed computing typically gains latency speedup through
    parallel processing; both Amdahl's law and Gustafson's law give
    theoretical speedups for parallel jobs \cite{amdahl1967law}
    \cite{gustafson1988law}. In addition, each node typically adds more working
    memory to the distributed system, allowing for larger datasets to be
    manipulated in-memory. For exceedingly large datasets, the benefits of
    distributed file systems commonly allow for resiliant storage, with
    well-regarded examples including HDFS and the Google File System it is
    based upon \cite{shvachko2010hadoop}\cite{ghemawat2003google}.
  \item[Evaluation of User-Specified Code]
    The ability to make use of user-specified code in processing. Most R
    packages for large-scale computing interact well with arbitrary code,
    however they typically have some limitations, such as an inability to
    recognise global variables, as is the case with sparklyr and to a lesser
    extent future \cite{sparklyr2020limitations}\cite{microsoft20}.
  \item[Native Support for Iteration]
    The ability to process user-specified code involving iteration over the
    whole dataset natively, keeping results in memory between iterations.
    This reflects the inherently iterative nature of many statistical
    algorithms. Furthermore, this shouldn't initiate a new job or process
    for every new iteration. This is seen as important enough that it serves
    as a major motivating factor behind Spark's development, overcoming a
    perceived major deficiency of Hadoop by Spark's developers
    \cite{zaharia2010spark}.
  \item[Object Persistence at Nodes]
    The ability to retain objects in-memory at their point of processing.
    The standard motivation for such a feature revolves around a reduction
    in data movement, which serves to slow down processing enormously
    through forcing programs to be I/O bound. In-memory persistence is
    closely related to the capacity for iterative code evaluation in a
    distributed system, and was similarly referenced by the Spark developers
    as an apparent benefit of Spark\cite{zaharia2010spark}.
  \item[Support for Distributed File Systems]
    Capacity to work with data and computation on distributed file systems,
    with a particular target of Hadoop Distributed File System (HDFS). As a
    well-established distributed file system, HDFS is targeted by a number
    of R packages, as well as serving as a file system base for other
    platforms such as spark \cite{analytics:_rhadoop_wiki}
    \cite{deltarho:_rhipe}\cite{urbanek20}\cite{zaharia2016apache}. HDFS offers
    several features that make it particularly attractive as a filesystem
    for a large-scale statistical analysis; being distributed and capable of
    running on commodity hardware allows for truly big data analysis. In
    addition, the system is built to be resiliant to hardware failure, so
    long-running analyses aren't cut short or forced to revert to a
    checkpoint because of singular component failure
    \cite{shvachko2010hadoop}.
  \item[Ease of Setup]
    Is setup suitable for a computationally-focussed statistician, or does
    it require a system administrator? At it's base, R is a statistical
    programming language \cite{rcore2020intro}. The particular skills of
    statisticians seldom correspond to the those requisite of system
    administration, with such a focus unlikely to compete successfully with
    their main research. Ease of deployment can determine a platform's
    success, with such a feature being one of the many motivations for the
    use and development of tools such as docker in recent years. The easiest
    possible setup would be a regular
    \mintinline{r}{install.packages()}, with no more than
    several lines specifying the platform configuration.
  \item[Inter-Node Communication]
    Can any pair of nodes communicate with each other, or do they only
    report to a master node? While many tasks process efficiently within a
    standard master-slave architecture, and inter-node communication is
    inherently expensive, there is still a large class of tasks that benefit
    from inter-node communication\cite{walker1996mpi}; particularly
    graph-based statistical methods.
  \item[Interactive Usage]
    The ability to make use of the package in an interactive R session,
    without mandatory batch execution. A major benefit of R as being
    interpreted is the availability of the REPL. The benefits of
    interactivity stemming from a REPL are well-documented, most notably
    aiding debugging \cite{mccarthy1978history}. For statistical analysese
    in particular, interactive analyses play a major role in exploratory
    data analysis, wherein insights can be tested and arrived at rapidly
    with an interactive session.
  \item[Backend Decoupling]
    The implementation is maintained entirely separately to the interface.
    This is standard in most of the performant parallel R systems as
    described by \cite{eddelbuettel2019parallel}, including foreach as a key
    example\cite{microsoft20}. As a software pattern, this is a case of
    separation of concerns, described in detail by \cite{dijkstra1982role}.
    Such a pattern fosters modularity and allows for a broader range of
    backends to be made use of, maximising the uptake of the platform. The
    ability for a system to adhere to a similar interface despite changes in
    internal behaviour is additionally useful for the sake of referential
    transparency, which prevents the need to rewrite programs upon making
    changes, as well as for human-computer interaction considerations
    \cite{sondergaard1990Rtda}\cite{norman2013design}. For example, the foreach
    package can change parallel adaptors in a single line of setup, without
    needing any changes made in the code referencing future, despite making
    use of a different internal interface \cite{weston19:_using}.
  \item[Evaluation of Arbitrary Classes]
    Any class, including user-defined classes, can be used in evaluation.
    There is proven value in rich user-defined objects, with the weight of
    much of the object-oriented programming paradigm serving to further that
    point \cite{dahl2004simula}. Conversely, many major packages limit
    themselves through provisioning only a few classes, such as pbdDMAT with
    distributed matrices, or the tidyverse and it's derivatives including
    sparklyr with ``tibbles'' \cite{pbdDMATpackage}\cite{wickham2019welcome}
  \item[Package-specific API]
    The platform is primarily explicitly programmed against at a
    package-specific interface. This is in contrast to packages mostly
    providing methods which overload standard generics or language
    structure; at a loss of general transparency, direct API's can ensure
    greater encapsulation and a closer mapping of code with the underlying
    implementation, thus potentially resulting in performance gains
    \cite{bierhoff2009api}. An example in R is the interface to the foreach
    package not overloading the existing for-loop syntax in R, but defining
    it's own specific interface \cite{microsoft20}.
  \item[Methods for Standard Generics]
    The platform is primarily programmed against using a polymorphic
    interface, with the package methods taking advantage of common generics.
    pbdDMAT takes this approach, as well as bigmemory, in providing
    matrix-like classes which are operated upon using standard matrix
    generics \cite{pbdDMATpackage}\cite{kane13:bigmemory}.
  \item[Methods for dplyr Generics]
    The platform makes use of dplyr functions as the primary set of generics
    to program over. Using a dplyr interface is a common trend in several R
    packages including sparklyr, disk.frame, and many database interfaces
    \cite{luraschi20}\cite{zj20}. Such an interface is claimed by the dplyr
    creators to aid beginners through being simple to remember
    \cite{wickham2019welcome}. In this way, it may serve to ease the
    learning curve for the platform.
\end{description}

\hypertarget{sec:comp-tab}{%
  \subsection{Comparison Table}\label{sec:comp-tab}}

\begin{table}[htbp]
  \centering\begin{tabular}{llllll}
    \toprule
    Feature                                                              & RHadoop                                                               & sparklyr                                      & pbdR                                        & disk.frame & foreach \\
    \midrule
    Distributed Computation                                              & yes\footnote{Use of HDFS through
      rhdfs\cite{revo2013rhdfs}, and MapReduce through
    rmr2\cite{revo2014plyrmr}}                                           & yes\footnote{Use of
    Spark\cite{luraschi20}}                                              & yes\footnote{Distributed computation
      performed by pbdMPI, with support for several remote messaging
    protocols\cite{Chen2012pbdMPIpackage}\cite{Schmidt2015pbdCSpackage}} & no
                                                                         & yes\footnote{Through the use of additional packages such as doMPI and
    sparklyr\cite{weston17}\cite{luraschi20}}                                                                                                                                                                                                                         \\
    Evaluation of User-Specified Code                                    & yes\footnote{rmr2\cite{revo2015rmr2}
    allows for arbitrary R code to be executed through MapReduce}        &
    mostly\footnote{Provides \mintinline{r}{mutate()}
      function to enable user-defined code, however there are limitations in
    not being capable of parsing global variables}                       & mostly\footnote{Adhering
    to a SPMD paradigm}                                                  & some\footnote{Many functions used for grouped
      summarisation are only estimates, such as
    \mintinline{r}{median}\cite{zj19:_group_by}}                         & mostly\footnote{\mintinline{r}{\%dopar\%}
      accepts any expression, and tries its best to handle references to
      global variables, however it is still recommended to manually define
    the global references as well as packages used}                                                                                                                                                                                                                   \\
    Native Support for Iteration                                         & no                                                                    & no\footnote{See
    doc/review-sparklyr-iteration.tex}                                   & yes                                                                   & no{3x4}                                       &
    no\footnote{foreach makes use of iterators, which can be defined to
      perform recurrance relations (see doc/review-foreach.tex, subsection
      ``Form of Iteration'') but these rely on closures and may in fact be
    slower than serial relations}                                                                                                                                                                                                                                     \\
    Object Persistence at Nodes                                          & no                                                                    & yes\footnote{See {2x3}}                       & yes
                                                                         & NA                                                                    & no                                                                                                                 \\
    Support for Distributed File Systems                                 & yes\footnote{Direct access to
    HDFS through rhdfs\cite{revo2013rhdfs}}                              & yes\footnote{Allows for
      Spark over HDFS, but offers no HDFS-specific filesystem manipulation
    functions}                                                           & no                                                                    & no                                            & yes\footnote{Through sparklyr as a backend}                        \\
    Ease of Setup                                                        & mediocre\footnote{Source repositories only exist on
      GitHub, following a non-standard package structure at the root level,
    and Hadoop is required to be set up beforehand}                      &
    acceptable\footnote{Installs from CRAN, requires Spark set up beforehand
    and environmental variables configured}                              & acceptable\footnote{Installation
      can be performed with
      \mintinline{r}{install.packages()} alongside the
    installation of \mintinline{r}{openmpi} externally}                  & simple                                                                & simple                                                                                                             \\
    Inter-Node Communication                                             & no                                                                    & no                                            & yes\footnote{Inter-node
      communication facilitated through pbdMPI wrappers to standard MPI
      communication functions such as \mintinline{r}{scatter}, \mintinline{r}{gather},
    \mintinline{r}{send}, etc.}                                          & NA                                                                    & no                                                                                                                 \\
    Interactive Usage                                                    & yes                                                                   & yes                                           & no                                          & yes        & yes     \\
    Backend Decoupling                                                   & no\footnote{While the collection is separate from
      Hadoop, it is entirely tied to Hadoop and MapReduce, and can't be
    switched to any other distributed platform}                          & no\footnote{Package tied
    to Spark as evaluative backend}                                      & no\footnote{Tied to the usage of the
    MPI protocol}                                                        & no                                                                    & yes                                                                                                                \\
    Evaluation of Arbitrary Classes                                      & yes\footnote{Within the
      \mintinline{r}{mapreduce()} function from rmr2, no
    prescription is given for any particular class over another}         &
    some\footnote{S3 Objects that have an
      \mintinline{r}{sdf_import()} method implemented can
      make use of the \mintinline{r}{sdf_copy_to()}
    function to copy objects from R to Spark}                            & yes\footnote{Arbitrary
      classes may be made use of and passed through the communicator
    generics when methods are defined for them, using pbdMPI}            & no                                                                    &
    yes\footnote{foreach makes use of iterator objects, which any class can
    inherit from to define \mintinline{r}{nextElem()}}                                                                                                                                                                                                                \\
    Package-specific API                                                 & yes\footnote{rmr2 has the package-specific
      \mintinline{r}{mapreduce()} function as the primary
    interface}                                                           & yes                                                                   & yes\footnote{pbdMPI provides package-specific
    generics to use and define further methods for}                      & no                                                                    & yes                                                                                                                \\
    Methods for Standard Generics                                        & no                                                                    & no                                            & some\footnote{pbdDMAT provides
      a distributed matrix class with methods defined to make transparent
    usage of standard matrix manipulation generics}                      & no                                                                    & no                                                                                                                 \\
    Methods for dplyr Generics                                           & no\footnote{The collection has suffered
      from the lack of updates; plyrmr provides functionality that is
      near-transparent to plyr, but this is still some distance from
    dplyr\cite{revo2014plyrmr}.}                                         & yes\footnote{The principal interaction
    is via dplyr generics, albeit with a difference of lazy evaluation}  &
    no                                                                   & yes                                                                   & no                                                                                                                 \\
    \bottomrule
  \end{tabular}
  \caption{Comparison of common large scale features among major R packages}
  \label{tab:comp-feat}
\end{table}