As described in Section \cref{sec:dag}, a lineage for each chunk is stored alongside it.
What this may imply for checkpointing is explored in this section.

In order to back up data, which may be later restored in the face of machine failure, checkpoints of individual chunks may be taken\cite{elnozahy2002recovery}.

For all practical purposes, not every single chunk can be checkpointed.
The amount of time spent writing to disk, or replicating across machines, is significant and will slow the system.
As such, the non-trivial decision of which chunks to checkpoint, and how to to restore from sparse checkpoints, serves as the basis of this discussion.

A variety of mechanisms may be used to trigger the designation of a node as a checkpoint, as well as methods of checkpointing.
The methods of checkpointing include redundancy along the cluster, or dumping the data structure to disk; dumping is favoured in this discussion due to the easier reasoning, but either could be considered or even combined without loss in generality\cite{walters2009replication}.
Triggers for checkpointing may be classified into whether they occur at the creation of the node, or during it's lifetime.

Given that each node retains a reference to it's direct prerequisites, information on the dependencies is easily accessed, and may be propagated along the graph as each new node is added.
This fact can be taken advantage of in order to implement creation-based checkpointing, in aid of fault-tolerance.

I suggest a time-to-recover checkpointing scheme, which attempts to checkpoint based on reaching a certain limit for how long it would take for the system to recover in the face of a worst-case fault, such as a total power outage.
This is performed through recording how long it takes to independently generate each chunk, and recording that information in the node associated with the chunk.
Each chunk also takes the maximum generation time from each of it's direct prerequisites and adds that to it's own time, in order to create a cumulative generation time, in a similar fashion to a Merkle tree or blockchain where properties of nodes accumulate along references, though without the cryptographic properties\cite{merkle1988tree}\cite{nakamoto2008bitcoin}.
When the pre-defined cumulative generation time limit is reached, the chunk at which the recorded limit is reached is designated for checkpointing, and the cumulative generation time resets (zeroes) for it's dependencies.

Limits on chain length can be placed similarly, where instead of time, a maximum count of nodes forming the path back to the originating checkpoint can be taken, with checkpointing taking place upon reaching the limit.

Dynamic checkpointing, taking place after node creation, may be used to checkpoint upon certain memory thresholds being reached in the chunk host, with a full dump to disk and system stall, before any system crash.

My suggestion for the restoration of the system to current working state following node failure, from sparse checkpoints, can be performed in the following manner;
If each node retains a record of the precise function used to create it's chunk, along with references to the chunks required by the function (it's immediate prerequisites), then it has an effective delta encoding to represent means of attaining one chunk from a prerequisite, and the graph of dependencies can be seen as a complete record of the construction of chunks, somewhat akin to a function-based, rather than line-based, git\cite{chacon2014progit}.
As such, any given node may be reconstructed by recursively walking back over the graph along the dependencies of nodes, collecting the required difference functions in a stack, until arriving at checkpoints, or leaf nodes representing file reads.
Upon reaching the checkpoints or leaves, ordered application of all of the accumulated difference functions through popping the stack, should result in the recreation of the node to be restored, assuming referential transparency.
Restoration from checkpoints serves effectively for enabling fault-tolerance in this respect.

\subsubsection{Self-Pruning of Dependency DAG's}

Up to this point, the graph as described has been append-only.
With such a description, it will grow excessively large, creating memory and traversal issues.
In conjunction with checkpointing, I consider a means of pruning the graph, keeping it to the minimum size necessary for recovery of the current state of the system.
While the checkpointing has not been implemented, the pruning has been implemented in a more brute-force manner (given in Section \cref{sec:gc}) than described in this section.

First, it is necessary to recognise that nodes representing unreferenced chunks still serve the bare purpose of delineating an intermediate (delta) transformation to target referenced chunks at some point further along the dependency path\cite{mogul2002deltahttp}.
If some checkpointed nodes are placed in the path of one of these unreferenced delta nodes and all of the delta's target referenced chunks, the unreferenced delta node is no longer necessary, and may be pruned.

The task then becomes one of determining the unreferenced delta nodes that have all their dependency paths, if followed backwards, resulting in a checkpoint.
A reference counting algorithm suffices to reveal these nodes, when combined with the important observation that checkpoints shouldn't count as references.
There are then four rules for algorithm for node removal:
\begin{itemize}
	\item Every node has an target counter, as an integer, initialised at zero.
	\item The introduction of a target node must result in the unit incrementation of all of it's direct prerequisite's target counters.
	\item The removal of a target node, or a node becoming a checkpoint, must result in the unit decrementation of all of it's direct prerequisite's target counters.
	\item Unreferenced nodes with a target counter of zero are to be removed.
\end{itemize}
With these rules followed, unreferenced nodes with all targets resulting in checkpoints are immediately removed from the graph, thereby preserving the graph as being the minimum size required for restoration at the current point in time.
